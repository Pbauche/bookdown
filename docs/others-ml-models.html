<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Handout_V2</title>
  <meta name="description" content="Handout_V2">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Handout_V2" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Handout_V2" />
  
  
  

<meta name="author" content="Pierre Bauche">


<meta name="date" content="2018-10-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="time-series.html">
<link rel="next" href="caret-package-1.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.1/leaflet.js"></script>
<script src="libs/leaflet-providers-1.1.17/leaflet-providers.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.1/leaflet-providers-plugin.js"></script>
<link href="libs/leaflet-markercluster-1.0.5/MarkerCluster.css" rel="stylesheet" />
<link href="libs/leaflet-markercluster-1.0.5/MarkerCluster.Default.css" rel="stylesheet" />
<script src="libs/leaflet-markercluster-1.0.5/leaflet.markercluster.js"></script>
<script src="libs/leaflet-markercluster-1.0.5/leaflet.markercluster.freezable.js"></script>
<script src="libs/leaflet-markercluster-1.0.5/leaflet.markercluster.layersupport.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">somethings</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> <strong>Information</strong></a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#usefull-ressource"><i class="fa fa-check"></i><b>1.1</b> Usefull ressource</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#todo"><i class="fa fa-check"></i><b>1.2</b> todo</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#interesting-stuff"><i class="fa fa-check"></i><b>1.3</b> interesting stuff</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#hint"><i class="fa fa-check"></i><b>1.4</b> Hint</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="feature-engeneering.html"><a href="feature-engeneering.html"><i class="fa fa-check"></i><b>2</b> Feature engeneering</a><ul>
<li class="chapter" data-level="2.1" data-path="feature-engeneering.html"><a href="feature-engeneering.html#input-feature"><i class="fa fa-check"></i><b>2.1</b> Input feature</a><ul>
<li class="chapter" data-level="2.1.1" data-path="feature-engeneering.html"><a href="feature-engeneering.html#numeric-data"><i class="fa fa-check"></i><b>2.1.1</b> Numeric Data</a></li>
<li class="chapter" data-level="2.1.2" data-path="feature-engeneering.html"><a href="feature-engeneering.html#count-data"><i class="fa fa-check"></i><b>2.1.2</b> count data</a></li>
<li class="chapter" data-level="2.1.3" data-path="feature-engeneering.html"><a href="feature-engeneering.html#categorical-data"><i class="fa fa-check"></i><b>2.1.3</b> categorical data</a></li>
<li class="chapter" data-level="2.1.4" data-path="feature-engeneering.html"><a href="feature-engeneering.html#date-time-lubridate-package"><i class="fa fa-check"></i><b>2.1.4</b> Date Time : Lubridate package</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="feature-engeneering.html"><a href="feature-engeneering.html#missing-value"><i class="fa fa-check"></i><b>2.2</b> Missing Value</a></li>
<li class="chapter" data-level="2.3" data-path="feature-engeneering.html"><a href="feature-engeneering.html#outlier-detection"><i class="fa fa-check"></i><b>2.3</b> Outlier Detection</a></li>
<li class="chapter" data-level="2.4" data-path="feature-engeneering.html"><a href="feature-engeneering.html#sampling-and-resampling"><i class="fa fa-check"></i><b>2.4</b> Sampling and resampling</a></li>
<li class="chapter" data-level="2.5" data-path="feature-engeneering.html"><a href="feature-engeneering.html#variables-selections"><i class="fa fa-check"></i><b>2.5</b> variables selections</a><ul>
<li class="chapter" data-level="2.5.1" data-path="feature-engeneering.html"><a href="feature-engeneering.html#filter-methods"><i class="fa fa-check"></i><b>2.5.1</b> Filter methods :</a></li>
<li class="chapter" data-level="2.5.2" data-path="feature-engeneering.html"><a href="feature-engeneering.html#wrapper-methods"><i class="fa fa-check"></i><b>2.5.2</b> Wrapper Methods:</a></li>
<li class="chapter" data-level="2.5.3" data-path="feature-engeneering.html"><a href="feature-engeneering.html#embedded-methods"><i class="fa fa-check"></i><b>2.5.3</b> Embedded Methods :</a></li>
<li class="chapter" data-level="2.5.4" data-path="feature-engeneering.html"><a href="feature-engeneering.html#dimension-reduction"><i class="fa fa-check"></i><b>2.5.4</b> Dimension reduction :</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="feature-engeneering.html"><a href="feature-engeneering.html#example"><i class="fa fa-check"></i><b>2.6</b> Example</a><ul>
<li class="chapter" data-level="2.6.1" data-path="feature-engeneering.html"><a href="feature-engeneering.html#credit-risk-modeling"><i class="fa fa-check"></i><b>2.6.1</b> Credit risk modeling</a></li>
<li class="chapter" data-level="2.6.2" data-path="feature-engeneering.html"><a href="feature-engeneering.html#variance-treshold-approach"><i class="fa fa-check"></i><b>2.6.2</b> variance treshold approach</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="feature-engeneering.html"><a href="feature-engeneering.html#method-summary"><i class="fa fa-check"></i><b>2.7</b> Method Summary</a></li>
<li class="chapter" data-level="2.8" data-path="feature-engeneering.html"><a href="feature-engeneering.html#tips"><i class="fa fa-check"></i><b>2.8</b> tips</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>3</b> Data visualization</a><ul>
<li class="chapter" data-level="3.1" data-path="data-visualization.html"><a href="data-visualization.html#descriptive"><i class="fa fa-check"></i><b>3.1</b> Descriptive</a></li>
<li class="chapter" data-level="3.2" data-path="data-visualization.html"><a href="data-visualization.html#caret-package"><i class="fa fa-check"></i><b>3.2</b> Caret Package</a></li>
<li class="chapter" data-level="3.3" data-path="data-visualization.html"><a href="data-visualization.html#spacial-map"><i class="fa fa-check"></i><b>3.3</b> Spacial map</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>4</b> Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="regression.html"><a href="regression.html#introduction"><i class="fa fa-check"></i><b>4.1</b> introduction</a></li>
<li class="chapter" data-level="4.2" data-path="regression.html"><a href="regression.html#linear-regression"><i class="fa fa-check"></i><b>4.2</b> Linear regression</a></li>
<li class="chapter" data-level="4.3" data-path="regression.html"><a href="regression.html#anova"><i class="fa fa-check"></i><b>4.3</b> ANOVA</a></li>
<li class="chapter" data-level="4.4" data-path="regression.html"><a href="regression.html#polynomiale-regression"><i class="fa fa-check"></i><b>4.4</b> Polynomiale regression</a></li>
<li class="chapter" data-level="4.5" data-path="regression.html"><a href="regression.html#logistique"><i class="fa fa-check"></i><b>4.5</b> Logistique</a><ul>
<li class="chapter" data-level="4.5.1" data-path="regression.html"><a href="regression.html#general"><i class="fa fa-check"></i><b>4.5.1</b> General</a></li>
<li class="chapter" data-level="4.5.2" data-path="regression.html"><a href="regression.html#binomial-logistic-model"><i class="fa fa-check"></i><b>4.5.2</b> Binomial Logistic MODEL</a></li>
<li class="chapter" data-level="4.5.3" data-path="regression.html"><a href="regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>4.5.3</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="regression.html"><a href="regression.html#generalized-linear-models"><i class="fa fa-check"></i><b>4.6</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="4.7" data-path="regression.html"><a href="regression.html#model-selection"><i class="fa fa-check"></i><b>4.7</b> Model Selection</a></li>
<li class="chapter" data-level="4.8" data-path="regression.html"><a href="regression.html#regularization-algorithms"><i class="fa fa-check"></i><b>4.8</b> Regularization Algorithms</a><ul>
<li class="chapter" data-level="4.8.1" data-path="regression.html"><a href="regression.html#ridge-regression"><i class="fa fa-check"></i><b>4.8.1</b> Ridge regression</a></li>
<li class="chapter" data-level="4.8.2" data-path="regression.html"><a href="regression.html#least-absolute-shrinkage-and-selection-operator-lasso"><i class="fa fa-check"></i><b>4.8.2</b> Least Absolute Shrinkage and Selection Opérator LASSO</a></li>
<li class="chapter" data-level="4.8.3" data-path="regression.html"><a href="regression.html#elastic-net"><i class="fa fa-check"></i><b>4.8.3</b> Elastic Net</a></li>
<li class="chapter" data-level="4.8.4" data-path="regression.html"><a href="regression.html#leas-angle-regression-lars"><i class="fa fa-check"></i><b>4.8.4</b> Leas-Angle Regression LARS</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="regression.html"><a href="regression.html#locally-estimated-scaterplot-smoothing-loess"><i class="fa fa-check"></i><b>4.9</b> Locally estimated Scaterplot Smoothing (LOESS)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>5</b> Unsupervised</a><ul>
<li class="chapter" data-level="5.1" data-path="unsupervised.html"><a href="unsupervised.html#dimensionality-reduction-algorithms"><i class="fa fa-check"></i><b>5.1</b> Dimensionality reduction algorithms</a></li>
<li class="chapter" data-level="5.2" data-path="unsupervised.html"><a href="unsupervised.html#cluster-analysis"><i class="fa fa-check"></i><b>5.2</b> Cluster analysis</a></li>
<li class="chapter" data-level="5.3" data-path="unsupervised.html"><a href="unsupervised.html#evaluation-of-clustering"><i class="fa fa-check"></i><b>5.3</b> Evaluation of clustering</a></li>
<li class="chapter" data-level="5.4" data-path="unsupervised.html"><a href="unsupervised.html#association-rule-mining-algorithms"><i class="fa fa-check"></i><b>5.4</b> Association Rule Mining Algorithms</a></li>
<li class="chapter" data-level="5.5" data-path="unsupervised.html"><a href="unsupervised.html#singular-value-decomposition"><i class="fa fa-check"></i><b>5.5</b> Singular Value decomposition</a></li>
<li class="chapter" data-level="5.6" data-path="unsupervised.html"><a href="unsupervised.html#k-nearest-neighbot"><i class="fa fa-check"></i><b>5.6</b> K-Nearest Neighbot</a></li>
<li class="chapter" data-level="5.7" data-path="unsupervised.html"><a href="unsupervised.html#others-unsuppervised-algorithms"><i class="fa fa-check"></i><b>5.7</b> Others unsuppervised algorithms</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="decision-tree.html"><a href="decision-tree.html"><i class="fa fa-check"></i><b>6</b> Decision Tree</a><ul>
<li class="chapter" data-level="6.1" data-path="decision-tree.html"><a href="decision-tree.html#type-of-decision-tree"><i class="fa fa-check"></i><b>6.1</b> Type of décision tree</a></li>
<li class="chapter" data-level="6.2" data-path="decision-tree.html"><a href="decision-tree.html#decision-measures-measure-of-node-purity-heterogeneity-of-the-node"><i class="fa fa-check"></i><b>6.2</b> Decision measures : measure of node purity (heterogeneity of the node)</a></li>
<li class="chapter" data-level="6.3" data-path="decision-tree.html"><a href="decision-tree.html#decision-tree-learning-methods"><i class="fa fa-check"></i><b>6.3</b> Decision tree learning methods</a></li>
<li class="chapter" data-level="6.4" data-path="decision-tree.html"><a href="decision-tree.html#random-forests"><i class="fa fa-check"></i><b>6.4</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="neural-network.html"><a href="neural-network.html"><i class="fa fa-check"></i><b>7</b> Neural Network</a><ul>
<li class="chapter" data-level="7.1" data-path="neural-network.html"><a href="neural-network.html#neural-networks-basis"><i class="fa fa-check"></i><b>7.1</b> Neural Networks Basis</a></li>
<li class="chapter" data-level="7.2" data-path="neural-network.html"><a href="neural-network.html#neural-network-architecture"><i class="fa fa-check"></i><b>7.2</b> Neural Network Architecture</a></li>
<li class="chapter" data-level="7.3" data-path="neural-network.html"><a href="neural-network.html#deep-learning"><i class="fa fa-check"></i><b>7.3</b> Deep Learning</a><ul>
<li class="chapter" data-level="7.3.1" data-path="neural-network.html"><a href="neural-network.html#example-of-deep-learning-classification"><i class="fa fa-check"></i><b>7.3.1</b> Example of deep learning : Classification</a></li>
<li class="chapter" data-level="7.3.2" data-path="neural-network.html"><a href="neural-network.html#example-imagine-prediction-nn-classification"><i class="fa fa-check"></i><b>7.3.2</b> Example : Imagine prediction : NN classification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>8</b> Text Mining</a><ul>
<li class="chapter" data-level="8.1" data-path="text-mining.html"><a href="text-mining.html#tf---idf"><i class="fa fa-check"></i><b>8.1</b> TF - IDF</a></li>
<li class="chapter" data-level="8.2" data-path="text-mining.html"><a href="text-mining.html#text-summarization-gong-liu-method-2001-via-latent-semantic-analysis"><i class="fa fa-check"></i><b>8.2</b> Text summarization : Gong &amp; Liu method (2001) via latent semantic analysis</a></li>
<li class="chapter" data-level="8.3" data-path="text-mining.html"><a href="text-mining.html#text-analysis"><i class="fa fa-check"></i><b>8.3</b> Text analysis</a></li>
<li class="chapter" data-level="8.4" data-path="text-mining.html"><a href="text-mining.html#other-topic"><i class="fa fa-check"></i><b>8.4</b> Other topic</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bayes-analysis.html"><a href="bayes-analysis.html"><i class="fa fa-check"></i><b>9</b> Bayes Analysis</a><ul>
<li class="chapter" data-level="9.1" data-path="bayes-analysis.html"><a href="bayes-analysis.html#introduction-au-bayseien"><i class="fa fa-check"></i><b>9.1</b> Introduction au bayseien</a></li>
<li class="chapter" data-level="9.2" data-path="bayes-analysis.html"><a href="bayes-analysis.html#naive-bayes"><i class="fa fa-check"></i><b>9.2</b> NAive bayes</a></li>
<li class="chapter" data-level="9.3" data-path="bayes-analysis.html"><a href="bayes-analysis.html#other-bayes-model"><i class="fa fa-check"></i><b>9.3</b> Other bayes model</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>10</b> Time Series</a></li>
<li class="chapter" data-level="11" data-path="others-ml-models.html"><a href="others-ml-models.html"><i class="fa fa-check"></i><b>11</b> Others ML models</a><ul>
<li class="chapter" data-level="11.1" data-path="others-ml-models.html"><a href="others-ml-models.html#support-vector-machines"><i class="fa fa-check"></i><b>11.1</b> Support Vector Machines</a></li>
<li class="chapter" data-level="11.2" data-path="others-ml-models.html"><a href="others-ml-models.html#hadoop-introduction"><i class="fa fa-check"></i><b>11.2</b> Hadoop introduction</a></li>
<li class="chapter" data-level="11.3" data-path="others-ml-models.html"><a href="others-ml-models.html#machine-learning-in-r-with-spark"><i class="fa fa-check"></i><b>11.3</b> Machine Learning in R with Spark</a></li>
<li class="chapter" data-level="11.4" data-path="others-ml-models.html"><a href="others-ml-models.html#machine-learning-in-r-with-h20"><i class="fa fa-check"></i><b>11.4</b> Machine learning in R with H20</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="caret-package-1.html"><a href="caret-package-1.html"><i class="fa fa-check"></i><b>12</b> Caret Package</a><ul>
<li class="chapter" data-level="12.1" data-path="caret-package-1.html"><a href="caret-package-1.html#pre-processing"><i class="fa fa-check"></i><b>12.1</b> Pre-Processing</a></li>
<li class="chapter" data-level="12.2" data-path="caret-package-1.html"><a href="caret-package-1.html#data-splitting"><i class="fa fa-check"></i><b>12.2</b> Data Splitting</a></li>
<li class="chapter" data-level="12.3" data-path="caret-package-1.html"><a href="caret-package-1.html#model-training-and-tuning"><i class="fa fa-check"></i><b>12.3</b> Model Training and tuning</a><ul>
<li class="chapter" data-level="12.3.1" data-path="caret-package-1.html"><a href="caret-package-1.html#exemple-basic-tuning-for-boosted-tree-model-gbm"><i class="fa fa-check"></i><b>12.3.1</b> Exemple : Basic tuning for boosted tree model GBM</a></li>
<li class="chapter" data-level="12.3.2" data-path="caret-package-1.html"><a href="caret-package-1.html#customizing-the-tuning-process"><i class="fa fa-check"></i><b>12.3.2</b> Customizing the Tuning Process</a></li>
<li class="chapter" data-level="12.3.3" data-path="caret-package-1.html"><a href="caret-package-1.html#exploring-and-comparing-resampling-distributions"><i class="fa fa-check"></i><b>12.3.3</b> Exploring and Comparing Resampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="caret-package-1.html"><a href="caret-package-1.html#best-available-models"><i class="fa fa-check"></i><b>12.4</b> Best available Models</a></li>
<li class="chapter" data-level="12.5" data-path="caret-package-1.html"><a href="caret-package-1.html#parallel-processing"><i class="fa fa-check"></i><b>12.5</b> Parallel Processing</a></li>
<li class="chapter" data-level="12.6" data-path="caret-package-1.html"><a href="caret-package-1.html#subsampling-for-class-imbalances"><i class="fa fa-check"></i><b>12.6</b> Subsampling for class imbalances</a></li>
<li class="chapter" data-level="12.7" data-path="caret-package-1.html"><a href="caret-package-1.html#variables-importance"><i class="fa fa-check"></i><b>12.7</b> Variables importance</a></li>
<li class="chapter" data-level="12.8" data-path="caret-package-1.html"><a href="caret-package-1.html#measurung-performance"><i class="fa fa-check"></i><b>12.8</b> measurung performance</a></li>
<li class="chapter" data-level="12.9" data-path="caret-package-1.html"><a href="caret-package-1.html#feature-selection"><i class="fa fa-check"></i><b>12.9</b> feature selection</a><ul>
<li class="chapter" data-level="12.9.1" data-path="caret-package-1.html"><a href="caret-package-1.html#overview"><i class="fa fa-check"></i><b>12.9.1</b> Overview</a></li>
<li class="chapter" data-level="12.9.2" data-path="caret-package-1.html"><a href="caret-package-1.html#univariate-approach"><i class="fa fa-check"></i><b>12.9.2</b> Univariate approach</a></li>
<li class="chapter" data-level="12.9.3" data-path="caret-package-1.html"><a href="caret-package-1.html#recursive-feature-elimination"><i class="fa fa-check"></i><b>12.9.3</b> recursive feature elimination</a></li>
<li class="chapter" data-level="12.9.4" data-path="caret-package-1.html"><a href="caret-package-1.html#genetic-algorimth"><i class="fa fa-check"></i><b>12.9.4</b> genetic algorimth</a></li>
<li class="chapter" data-level="12.9.5" data-path="caret-package-1.html"><a href="caret-package-1.html#simulated-annealing"><i class="fa fa-check"></i><b>12.9.5</b> simulated annealing</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Handout_V2</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="others-ml-models" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Others ML models</h1>
<div id="support-vector-machines" class="section level2">
<h2><span class="header-section-number">11.1</span> Support Vector Machines</h2>
<ul>
<li><strong>SVM</strong> A distance-based algorithm, trés bon pour la classification binaire dans les big dataset. Can deal with nonlinearity, overlapping classes, … etc.
<ul>
<li><p>Classe separation : SVM Cherche the optimal hyperplane separating 2 classe by maximizing the margin between the closest points. The point lying on the margins are the Support Vectors. The line passing through the midpoint of the margins is the optimal hyperplane. <img src="C:/Users/007/Desktop/Data%20science%20with%20R/R/img/SVM.PNG" alt="SVM" /></p></li>
<li>Overlapping classe : Si point on the wring side, il peut etre pond?rer pour r?duire sont influence. On utilise the Hinge loss function qui est proportionnel a la distince from the margin/</li>
<li><p>Non liearity : Si une séparation linéaire ne peut etre trouvé, les observations sont projeté dans un espace a plus haute dimension using a kernel function ou les observations deviennent linéairement séparable. One popular Gaussian family kernel is the radial basis function. A radial basis function (RBF) is a real-valued function whose value depends only on the distance from the origin $ K(x,y) = (- ) $ . Il existe d’autre fonction kernel, kernel refet to a window function that is zero-valued outside of some chosen interval.</p></li>
</ul></li>
</ul>
<blockquote>
<p>c’est donc un probleme de minisation des distances</p>
</blockquote>
<ul>
<li><strong>Binary SVM Classifier</strong></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(e1071)
<span class="kw">library</span>(rpart)
<span class="kw">library</span>(gmodels)

### data pre <span class="al">###</span>
breast_cancer_data &lt;-<span class="kw">read.table</span>(<span class="st">&quot;C:/Users/007/Desktop/Data science with R/R/Dataset/Chapter 6/breast-cancer-wisconsin.data.txt&quot;</span>,<span class="dt">sep=</span><span class="st">&quot;,&quot;</span>)
breast_cancer_data<span class="op">$</span>V11 =<span class="kw">as.factor</span>(breast_cancer_data<span class="op">$</span>V11)

<span class="co"># split data into a train and test set</span>
index &lt;-<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(breast_cancer_data)
test_data_index &lt;-<span class="kw">sample</span>(index, <span class="kw">trunc</span>(<span class="kw">length</span>(index)<span class="op">/</span><span class="dv">3</span>))
test_data &lt;-breast_cancer_data[test_data_index,]
train_data &lt;-breast_cancer_data[<span class="op">-</span>test_data_index,]

<span class="co"># model</span>
svm.model &lt;-<span class="kw">svm</span>(V11 <span class="op">~</span>., <span class="dt">data =</span> train_data, <span class="dt">cost =</span><span class="dv">100</span>, <span class="dt">gamma =</span><span class="dv">1</span>)

<span class="co"># note : in realworld dataset accurancy of 100% is not possible </span>
<span class="co"># but un medical dignostic il est important d&#39;etre proche</span>

svm_pred_train &lt;-<span class="kw">predict</span>(svm.model, train_data[,<span class="op">-</span><span class="dv">11</span>])
<span class="kw">CrossTable</span>(train_data<span class="op">$</span>V11, svm_pred_train, <span class="dt">prop.chisq =</span><span class="ot">FALSE</span>, <span class="dt">prop.c =</span><span class="ot">FALSE</span>, <span class="dt">prop.r =</span><span class="ot">FALSE</span>, <span class="dt">dnn =</span><span class="kw">c</span>(<span class="st">&#39;actual default&#39;</span>, <span class="st">&#39;predicted default&#39;</span>))</code></pre></div>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |         N / Table Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  466 
## 
##  
##                | predicted default 
## actual default |         2 |         4 | Row Total | 
## ---------------|-----------|-----------|-----------|
##              2 |       292 |         0 |       292 | 
##                |     0.627 |     0.000 |           | 
## ---------------|-----------|-----------|-----------|
##              4 |         0 |       174 |       174 | 
##                |     0.000 |     0.373 |           | 
## ---------------|-----------|-----------|-----------|
##   Column Total |       292 |       174 |       466 | 
## ---------------|-----------|-----------|-----------|
## 
## </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">svm_pred_test &lt;-<span class="kw">predict</span>(svm.model, test_data[,<span class="op">-</span><span class="dv">11</span>])
<span class="kw">CrossTable</span>(test_data<span class="op">$</span>V11, svm_pred_test,<span class="dt">prop.chisq =</span><span class="ot">FALSE</span>, <span class="dt">prop.c =</span><span class="ot">FALSE</span>, <span class="dt">prop.r =</span><span class="ot">FALSE</span>, <span class="dt">dnn =</span><span class="kw">c</span>(<span class="st">&#39;actual default&#39;</span>, <span class="st">&#39;predicted default&#39;</span>))</code></pre></div>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |         N / Table Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  233 
## 
##  
##                | predicted default 
## actual default |         2 |         4 | Row Total | 
## ---------------|-----------|-----------|-----------|
##              2 |       151 |        15 |       166 | 
##                |     0.648 |     0.064 |           | 
## ---------------|-----------|-----------|-----------|
##              4 |         0 |        67 |        67 | 
##                |     0.000 |     0.288 |           | 
## ---------------|-----------|-----------|-----------|
##   Column Total |       151 |        82 |       233 | 
## ---------------|-----------|-----------|-----------|
## 
## </code></pre>
<ul>
<li><strong>multiclasse SVM</strong> : SVM Peut etre étendu a du multiclasse by creating multible binary classifier.
<ul>
<li>create binary classifiers</li>
<li>between one class and the rest of the classes</li>
<li>between every pair of classe possibles</li>
<li>For any new cases, the SVM classifier adopts a winner-takes-all strategy, in which the class with highest output is assigned.</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>( <span class="st">&#39;e1071&#39;</span> )

Data_House_Worth &lt;-<span class="kw">read.csv</span>(<span class="st">&quot;C:/Users/007/Desktop/Data science with R/R/Dataset/Chapter 6//House Worth Data.csv&quot;</span>,<span class="dt">header=</span><span class="ot">TRUE</span>)

<span class="co"># model</span>

svm_multi_model &lt;-<span class="kw">svm</span>( HouseNetWorth <span class="op">~</span>StoreArea <span class="op">+</span>LawnArea, Data_House_Worth )
svm_multi_model</code></pre></div>
<pre><code>## 
## Call:
## svm(formula = HouseNetWorth ~ StoreArea + LawnArea, data = Data_House_Worth)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  radial 
##        cost:  1 
##       gamma:  0.5 
## 
## Number of Support Vectors:  120</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="kw">predict</span>( svm_multi_model, <span class="dt">newdata=</span>Data_House_Worth )

<span class="kw">table</span>(Data_House_Worth<span class="op">$</span>HouseNetWorth,res)</code></pre></div>
<pre><code>##         res
##          High Low Medium
##   High    122   1      7
##   Low       6 122      7
##   Medium    1   7     43</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">diag</span>(<span class="kw">table</span>(Data_House_Worth<span class="op">$</span>HouseNetWorth,res)))<span class="op">/</span><span class="kw">nrow</span>(Data_House_Worth)</code></pre></div>
<pre><code>## [1] 0.9082278</code></pre>
<p>SVM est un non probalistic binary classifier mais trés efficace. Peut sappliquer a la classification d’image, d’hypertext, character recognition, …</p>
</div>
<div id="hadoop-introduction" class="section level2">
<h2><span class="header-section-number">11.2</span> Hadoop introduction</h2>
<ul>
<li>Hadoop framework consists of the following three modules
<ul>
<li>Hadoop Distributed File System : This is the storage part of Hadoop</li>
<li>Hadoop YARN: This is also known as the data operating system.</li>
<li>Hadoop MapReduce: MapReduce decides the execution logic of what needs to be done with the data. The logic should be designed in such a way that it can execute in parallel with smaller chunks of data residing in a distributed cluster of machines.</li>
</ul></li>
</ul>
</div>
<div id="machine-learning-in-r-with-spark" class="section level2">
<h2><span class="header-section-number">11.3</span> Machine Learning in R with Spark</h2>
<ul>
<li>At a high level, it provides tools such as:
<ul>
<li>ML algorithms: Common learning algorithms such as classification, regression, clustering, and collaborative filtering</li>
<li>Featurization: Feature extraction, transformation, dimensionality reduction, and selection</li>
<li>Pipelines: Tools for constructing, evaluating, and tuning ML pipelines</li>
<li>Persistence: Saving and loading algorithms, models, and pipelines</li>
<li>Utilities: Linear algebra, statistics, data handling, etc.</li>
</ul></li>
</ul>
<blockquote>
<p>Need to be download : follow “data science using R, p 541”</p>
</blockquote>
</div>
<div id="machine-learning-in-r-with-h20" class="section level2">
<h2><span class="header-section-number">11.4</span> Machine learning in R with H20</h2>
<p>H2O is an open source high performance cluster for big data analysis. These techniques are not feasible to be executed on individual machines and need high-power computing. H2O is a Java Virtual Machine that is optimized for doing “in-memory” processing of distributed, parallel machine learning algorithms on clusters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;h2o&quot;)</span>
<span class="co"># Load the h2o library in R</span>
<span class="co">#library(h2o)</span>

<span class="co">#Initiate a cluster in your machine</span>
<span class="co">#localH2O =h2o.init</span>

<span class="co"># The function demo runs all at once and outputs the entire output at one go. However, for better understanding of what the function does, we have split the output and explainedeach part in detail.</span>

<span class="co"># demo = demo(h2o.deeplearning)</span>

<span class="co"># more demo : </span>
<span class="co"># demo(package = &quot;h2o&quot;)</span></code></pre></div>
<ul>
<li>Additional parameters are:
<ul>
<li>Hidden, which specifies the hidden layer sizes,</li>
<li>Activation, which specifies the type of activation function; the demo uses a Tanh function</li>
<li>epochs, which directs the neural network with “How many times the dataset should be iterated (streamed)</li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="time-series.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="caret-package-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["bookdown-start.pdf", "bookdown-start.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
